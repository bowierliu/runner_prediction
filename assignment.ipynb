{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f683e97c-2855-4b1f-b0d2-b9510dde9b5d",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "In this course assignment you must build a predictive model to determine what place a runner will come in in a foot race. More specifically, you must predict the place order for all participants running races in the year 2019 which are part of a series (e.g. they have been run annually, or at least once previously) using historical data. **For each race you must predict the integer place ordering for all participants**. You are not predicting the top n finishers, or performance bands where people will finish. Instead, your method is expected to be integrated into a premium feature of an application such as Strava, where historical data and data about the racer (and who is signed up for the race!) could be used to help build a personalized prediction for them.\n",
    "\n",
    "## Framing\n",
    "Through this assignment you will demonstrate your ability to build sophisticated supervised machine learning models, from data manipulation through feature engineering and modelling. This is an authentic dataset, and a real-world problem. You can use whatever modelling method you would like to, and can characterise the problem as a regression, classification, or ordinal prediction problem. There is no particular guidelines you must follow, nor guidance offered in the course _per se_ however, there is plenty of opportunity to ask course staff questions. **It is expected that this assignment will take significant effort**.\n",
    "\n",
    "## About the Data\n",
    "All of the races you are asked to predict outcomes for have a temporal relationship with some race in the past (e.g. they are part of an annual series), and I have included an identifier `sequence_id` to help identify this. The `sequence_id` will be included in all races you need to predict, so you can build race-specific features should you wish to. Races which are in your training set and do not have a `sequence_id` could be used however you might like. There may be some races which have a `sequence_id` in the training set but do not have a `sequence_id` in the holdout set -- this all depends what is offered in a given year!\n",
    "\n",
    "A couple of core concepts are important beyond sequences. First, races have categories, which generally (though doesn't need to) denote the length of the race (e.g. 5k, marathon, etc). I've cleaned this column into a new one, prepending the word `clean` so that a columns such as `category.completed.name` becomes `clean_category.completed.name`. I have left the original data in there for you as well, and the transformations I've done have been largely to reduce dimensionality along lines I think is reasonable.\n",
    "\n",
    "In addition to a category, there are `brackets`. Brackets typical denote demographic aspects of the runners and group them, such as Men aged 40-45. I have removed bracket information from the data and instead want you to focus on overall prediction which merges all runners in a given category together. This (should) line up with the rank order based on the individual's time, though I have not verified it (and predicting time is **not** the task).\n",
    "\n",
    "## Evaluation Criteria\n",
    "In this assignment you will be penalized equally for incorrect predictions weighted by the distance by which you are incorrect within a given race. It does not matter whether you over or under predicted a given rank, you are penalized one point per position you are off for a given individual. All DNF's are removed from the dataset, so each person in the dataset has a rank. You *must* provide a predicted rank for each person however, you may rank multiple people at the same spot if you would like (e.g. ties). The evaluation is for each combination of event and category, so a given event may have a 5 kilometer category, a 1 mile category, and so forth. Only individuals registered for a given event and category combination are included in the `DataFrame` you will be asked to predict for. Each event/category pair is equally weighted, and is scaled by the size of the event. Your overall prediction score will be the sum of all scores across the prediction tasks (e.g. across unique combinations of event and category). The exact scoring function is provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b18926-af2b-4b55-8dbb-f4af720df995",
   "metadata": {},
   "source": [
    "## Example Solution\n",
    "The following cell contains an example solution to demonstrate the API which is used for this assignment. In short, you are to create an `sklearn.pipeline.Pipeline` object which you `fit()` on your training data using whatever method you like and serialize it to disk in a file called `pipeline.cloudpickle`. This object will then be reinstantiated in the autograder and evaluated based on the scoring function described above. Please note that the solution below would be a poor one, it is intended **only** to demonstrate the API for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e630de46-9e08-43a4-93e5-eefe0eec48a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;customtransformer&#x27;, CustomTransformer()),\n",
       "                (&#x27;quantiletransformer&#x27;, QuantileTransformer()),\n",
       "                (&#x27;linearregression&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;customtransformer&#x27;, CustomTransformer()),\n",
       "                (&#x27;quantiletransformer&#x27;, QuantileTransformer()),\n",
       "                (&#x27;linearregression&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('customtransformer', CustomTransformer()),\n",
       "                ('quantiletransformer', QuantileTransformer()),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# This is a custom transformer to demonstrate how you might modify the data for feature\n",
    "# selection or engineering before applying a given model. In this example I am only\n",
    "# doing feature selection, and passing to the next element in the pipeline the age\n",
    "# and bib number for the runner. Thus only two features will be used in my predictive model.\n",
    "# There are other ways to do this\n",
    "class CustomTransformer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        # Just select the features we want\n",
    "        Xprime=X[['age','bib']]\n",
    "        # Ensure that they have numbers in them of the regression will fail\n",
    "        Xprime=Xprime.fillna(value=-1)\n",
    "        return Xprime\n",
    "\n",
    "# I build a very basic pipeline which is made up of three stages. In the first, my\n",
    "# custom transform is called and reduces the DataFrame to just two columns. In the\n",
    "# second I use a built-in transformer from sklearn to bucket users based on their\n",
    "# bib number, perhaps as a proxy for \"how early did they sign up\". In the final step\n",
    "# I want to use a LinearRegression() regressor.\n",
    "\n",
    "# There are two main concerns I need to address. First, I need to be resilient to bad\n",
    "# data which might address. So I know the LinearRegression() object can't handle\n",
    "# missing data, so I need to deal with that. This was done in the CustomeTransformer()\n",
    "# already.\n",
    "\n",
    "# Second, I actually need to be ranking results, not regressing. Depending upon your\n",
    "# model you need to consider this carefully. Here is a fine catch all if you\n",
    "# are using regression, and object which just ranks the results in order. This is\n",
    "# called monkey patching and replaces the LinearRegression() object's predict()\n",
    "# function with a wrapper\n",
    "reg=LinearRegression()\n",
    "reg.original_predict=reg.predict\n",
    "\n",
    "def new_predict(X):\n",
    "    # run the old regression method\n",
    "    rankings=reg.original_predict(X)\n",
    "    # now calculate and return the ranks of each item instead\n",
    "    # we need to add a +1 because the lowest rank is a 1, not a 0\n",
    "    # it's unfortunate, the first athletic competition was probably run by R users...\n",
    "    return rankings.squeeze().argsort()+1\n",
    "\n",
    "# Now we overwrite (monkey patch) the predict() function with our own implementation\n",
    "reg.predict=new_predict\n",
    "\n",
    "# And build our pipeline object\n",
    "pipe = make_pipeline( CustomTransformer(), QuantileTransformer(), reg )\n",
    "\n",
    "# This is just one way to do this, you could also implement a new estimator with the\n",
    "# predict interface and build all of your logic in there. The benefit of the\n",
    "# pipeline is that you can rapidly change the logic and try different pipelines using\n",
    "# common methods from sklearn. When the pipeline gets complicated, you can also\n",
    "# visualize it...\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)\n",
    "\n",
    "# Once the pipeline is built, we need to train it. I'm going to just do a pretty poor\n",
    "# job here, getting the training set provided\n",
    "df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# I'm just going to build a model off of one event/category combination (lame)\n",
    "training_data=df.query(\"`event.id`=='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "\n",
    "# And I'm going to pass in all of my potential columns for consideration. Note: The\n",
    "# example pipeline I built is going to reduce this to just the two columns I'm interested\n",
    "# in, so this is a safe thing to do. But be aware, the holdout set does not have all of\n",
    "# the data the training set might, because of leakage, so you need to think about this\n",
    "# and not make assumptions. You can see how I built the holdout set at the bottom of\n",
    "# this notebook\n",
    "X=set(training_data.columns)-{'overall_ranking'}\n",
    "\n",
    "# The ranking is what we aim to predict\n",
    "y={'overall_ranking'}\n",
    "\n",
    "# Now I fit() the pipeline. You'll note that the outcomes I need to squeeze() to ensure\n",
    "# it's a one dimensional structure and not a DataFrame\n",
    "fitted_pipe=pipe.fit(training_data[X],training_data[y].squeeze().to_numpy())\n",
    "\n",
    "# And now, assuming that I am happy with this model and think it is great, I write the\n",
    "# fitted pipeline to a file. This file will be read in by the autograder.\n",
    "cloudpickle.dump(fitted_pipe, open('pipeline.cloudpickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd81c74-0dc9-41b4-b496-23b068a086a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa01767a-076b-49e0-a7b8-ed62fb6166ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Function to convert miles to kilometers\n",
    "        def miles_to_km(distance_miles):\n",
    "            return distance_miles * 1.60934\n",
    "\n",
    "        # Function to round to the nearest competition distance\n",
    "        def round_to_nearest_race_distance(distance_km):\n",
    "            race_distances_km = [0, 5, 8, 10, 15, 21.1, 42.2]\n",
    "            return min(race_distances_km, key=lambda x: abs(x - distance_km))\n",
    "\n",
    "        # Apply the function conditionally\n",
    "        if 'category.registered.distance.quantity' in X.columns and 'category.registered.distance.unit' in X.columns:\n",
    "            X['category.registered.distance.quantity'] = X.apply(\n",
    "                lambda row: miles_to_km(row['category.registered.distance.quantity']) if row['category.registered.distance.unit'] == 'mi' else row['category.registered.distance.quantity'],\n",
    "                axis=1\n",
    "            )\n",
    "            X['category.registered.distance.quantity'] = X['category.registered.distance.quantity'].apply(round_to_nearest_race_distance)\n",
    "\n",
    "            # Update the unit column to 'km' where necessary\n",
    "            X['category.registered.distance.unit'] = X['category.registered.distance.unit'].apply(\n",
    "                lambda x: 'km' if x == 'mi' else x\n",
    "            )\n",
    "\n",
    "\n",
    "        # Define the mapping for the 'sex' column\n",
    "        sex_mapping = {\n",
    "            'Male': 0,\n",
    "            'M': 0,\n",
    "            'Female': 1,\n",
    "            'F': 1,\n",
    "            'NOT SPECIFIED': -1,\n",
    "            'Unspecified': -1,\n",
    "            np.nan: -1\n",
    "        }\n",
    "\n",
    "        # Replace the values in the 'sex' column if it exists\n",
    "        if 'sex' in X.columns:\n",
    "            X['sex'] = X['sex'].replace(sex_mapping)\n",
    "        \n",
    "        # Filter age to remove outliers\n",
    "        if 'age' in X.columns:\n",
    "            # Clip the ages to be within a reasonable range\n",
    "            X['age'] = X['age'].clip(lower=6, upper=80)\n",
    "\n",
    "        # Factorize 'event.id'\n",
    "        if 'event.id' in X.columns:\n",
    "            X['event_group'] = pd.factorize(X['event.id'])[0]\n",
    "            \n",
    "        # Factorize 'sequence_id'\n",
    "        if 'sequence_id' in X.columns:\n",
    "            X['sequence_id'] = pd.factorize(X['sequence_id'])[0]\n",
    "            \n",
    "        # Fill NaN values in the 'bib' column with 0\n",
    "        if 'bib' in X.columns:\n",
    "            X['bib'].fillna(0, inplace=True)\n",
    "            \n",
    "        # Factorize 'location.state'\n",
    "        if 'location.state' in X.columns:\n",
    "            X['location_state_encoded'] = pd.factorize(X['location.state'])[0]\n",
    "            X['location_state_encoded'] = X['location_state_encoded'].replace(-1, X['location_state_encoded'].max() + 1)\n",
    "            \n",
    "\n",
    "        # Define the categorization function with numerical values\n",
    "        def categorize_participants(registered):\n",
    "            if registered == 0:\n",
    "                return 0  # No Participants\n",
    "            elif registered <= 4510:\n",
    "                return 1  # Small Event\n",
    "            elif registered <= 10078:\n",
    "                return 2  # Medium Event\n",
    "            elif registered <= 13927:\n",
    "                return 3  # Large Event\n",
    "            elif registered <= 36528:\n",
    "                return 4  # Very Large Event\n",
    "\n",
    "            \n",
    "        # Fill NaN values in the 'counts.participants.registered' column with mode\n",
    "        if 'counts.participants.registered' in X.columns:\n",
    "            mode_value = X['counts.participants.registered'].mode()[0]\n",
    "            X['counts.participants.registered'].fillna(mode_value, inplace=True)\n",
    "            #X['participants_category'] = X['counts.participants.registered'].apply(categorize_participants)\n",
    "\n",
    "        # Calculate the ratio of males in each event\n",
    "        if 'event.id' in X.columns and 'sex' in X.columns:\n",
    "            male_ratio = X.groupby('event.id')['sex'].apply(lambda x: (x == 0).mean())\n",
    "            X = X.merge(male_ratio.rename('male_ratio'), on='event.id', how='left')\n",
    "        \n",
    "        # Fill price with mean of price grouped by event.id\n",
    "        if 'price' in X.columns:\n",
    "            X['price'] = X['price'].fillna(X.groupby('event.id')['price'].transform('mean'))\n",
    "            \n",
    "            #X['price'] = X['price'].apply(lambda x: 0 if pd.isna(x) or x == 0 else 1)\n",
    "\n",
    "        \n",
    "        # Hometown Match\n",
    "        X['hometown_match'] = X.apply(lambda row: 1 if pd.notna(row['result.hometown']) and pd.notna(row['location.name']) and row['result.hometown'] == row['location.name'] else 0, axis=1)\n",
    "        \n",
    "        \n",
    "        # Further eliminate columns that provide similar information\n",
    "        columns_to_keep = [\n",
    "            'age', 'sex',\n",
    "            'counts.participants.registered', \n",
    "            'bib', 'category.registered.distance.quantity', \n",
    "            'hometown_match', 'price', #'male_ratio'\n",
    "        ]\n",
    "\n",
    "        existing_columns = [col for col in columns_to_keep if col in X.columns]\n",
    "        X = X[existing_columns]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18bfdacf-14a5-4473-b578-80664814583c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "df = pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "df = df.dropna(subset=['overall_ranking'])\n",
    "events=df['event.id'].unique()\n",
    "\n",
    "train_set=events[0:102]\n",
    "holdout_set=events[102:146]\n",
    "\n",
    "train=df.query(\"`event.id` in @train_set\")\n",
    "#test=df.query(\"`event.id` in @test_set\")\n",
    "holdout=df.query(\"`event.id` in @holdout_set\")\n",
    "\n",
    "holdout=holdout.drop(\n",
    "    columns=['time.end',\n",
    "             'body.results_certificate',\n",
    "             'event.results_posted',\n",
    "             'event.results_posted',\n",
    "             'event.results_certificate',\n",
    "             'event.photos_available',\n",
    "             'event.photos_faces',\n",
    "             'event.photos_social_sharing',\n",
    "             'event.results_searchable',\n",
    "             'corral.id',\n",
    "             'corral.name',\n",
    "             'corral.wave',\n",
    "             'corral.time.close',\n",
    "             'corral.time.start',\n",
    "             'result.duration.chip',\n",
    "             'result.duration.pace',\n",
    "             'result.rankings',\n",
    "             'result.splits',\n",
    "             'result.videos',\n",
    "             'result.finished',\n",
    "             'result.disqualified',\n",
    "             'result.duration'])\n",
    "\n",
    "holdout=df.groupby([\"event.id\",\"clean_categories.name\"]).filter(lambda z: len(z)>5)\n",
    "\n",
    "# Prepare features and target for training and testing sets\n",
    "#X_train = train.drop(columns=['x_result.duration.chip'])\n",
    "#y_train = train['x_result.duration.chip']\n",
    "#X_test = test.drop(columns=['x_result.duration.chip'])\n",
    "#y_test = test['x_result.duration.chip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97cd5d4-3d98-479d-8eab-d5b4d14e669f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = pd.to_timedelta(train['result.duration.chip']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e6e6f81-b48a-46cd-8789-2c1f20c0c03d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the evaluation function\n",
    "def evaluation_function(x):\n",
    "    return pd.Series(x.squeeze()).rank().values\n",
    "\n",
    "# Create the TransformedTargetRegressor with RandomForestRegressor\n",
    "reg = TransformedTargetRegressor(\n",
    "    regressor=RandomForestRegressor(n_estimators=500, max_depth=10, random_state=42),\n",
    "    inverse_func=evaluation_function\n",
    ")\n",
    "\n",
    "# Create the pipeline with RandomForestRegressor\n",
    "pipe = Pipeline([\n",
    "    ('transformer', CustomTransformer()),\n",
    "    ('fill_missing', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    (\"regressor\", reg)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "fitted_pipe = pipe.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6dbbcd-da4e-4f10-b8f0-b3a9273bc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "# Save the fitted pipeline to a file\n",
    "with open('pipeline.cloudpickle', 'wb') as f:\n",
    "    cloudpickle.dump(fitted_pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f295b8-719a-460b-aacf-2f8142a10664",
   "metadata": {},
   "source": [
    "## Testing the Solution\n",
    "With a minimum pipeline built we can think about testing it. The code below simulates the autograder, and is something you can use to evaluate how your model performs. The most important function is the `score()` function, which demonstrates how the score of the model fitness will be determined, as described previously. This function just compares two ranked lists and determined how aligned they are with one another. The second function is the `evaluate()` function, which runs your model over a given race of data. Note that the evaluation generates new ranks from the `overall_ranking` but doesn't use those numbers directly. Those numbers are in-order, but due to underlying data assumptions may have gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa10c44c-2a38-417e-a40b-80d77ee593ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26725880179383893\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "# This code simulates the autograder. It is not the full autograder implementation\n",
    "# but shares an API with the autograder. It expects that your fitted pipeline is\n",
    "# submitted with the name pipeline.cloudpickle as demonstrated above. This object\n",
    "# must implement the predict() function. This is done automatically by the sklearn\n",
    "# Pipeline object if the last element of your pipeline is a classifier which has\n",
    "# a predict() function. If you are not submitting a Pipeline, and want to do something\n",
    "# different, you *must* have a predict() function of the same method signature, e.g.:\n",
    "#\n",
    "#   predict(self, X, **predict_params)->np.ndarray\n",
    "\n",
    "# Load holdout data, in this case I'll simulate it by loading the training data\n",
    "#df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# And evaluate on all 5k races that we didn't consider for training\n",
    "#holdout_data=df.query(\"`event.id`!='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "holdout_data=holdout\n",
    "\n",
    "# This is the scoring function to determine model fitness\n",
    "def score(left: pd.DataFrame, right: pd.DataFrame):\n",
    "    '''\n",
    "    Calculates the difference between the left and the right when considering rank of items. \n",
    "    This scoring function requires that the two DataFrames have identical indicies, and that\n",
    "    they each contain only one column of values and no missing values. Props to Blake Atkinson\n",
    "    for providing MWE indicating issues with autograder version #1.\n",
    "    '''\n",
    "    assert(type(left)==pd.DataFrame)\n",
    "    assert(type(right)==pd.DataFrame)\n",
    "    assert(len(left)==len(right))\n",
    "    assert(not np.any(np.isnan(left)))\n",
    "    assert(not np.any(np.isnan(right)))\n",
    "    assert(left.index.equals(right.index))\n",
    "    # convert to ndarrays\n",
    "    left=left.squeeze()\n",
    "    right=right.squeeze()\n",
    "    \n",
    "    return np.sum(np.abs(left-right))/(len(left)*(len(left)-1))\n",
    "\n",
    "# This function runs the prediction model agains a given event/category pair. It\n",
    "# intentionally loads the student model each time to avoid accidental leakage of data\n",
    "# between events.\n",
    "def evaluate(data, pipeline_file='pipeline.cloudpickle'):\n",
    "    # Load student pipeline\n",
    "    fitted_pipe = cloudpickle.load(open(pipeline_file,'rb'))\n",
    "    \n",
    "    # Separate out the X and y\n",
    "    X=list(set(data.columns)-{'overall_ranking'})\n",
    "    y=['overall_ranking']\n",
    "    \n",
    "    # Drop any missing results (DNFs)\n",
    "    data=data.dropna(subset=['overall_ranking'])\n",
    "    \n",
    "    # Ensure there is data to actually predict on\n",
    "    if len(data)==0:\n",
    "        return np.nan\n",
    "\n",
    "    # Predict on unseen data\n",
    "    predictions=pd.DataFrame(fitted_pipe.predict(data[X]),data.index)\n",
    "    observed=data[y]\n",
    "    \n",
    "    # Generate rankings within this bracket\n",
    "    observed=pd.DataFrame(data[y].rank(),data.index)\n",
    "    \n",
    "    # Return the ratio of the student score\n",
    "    return pd.Series({\"score\":score(observed,predictions)})\n",
    "\n",
    "# Student solution\n",
    "pipeline_file='pipeline.cloudpickle'\n",
    "\n",
    "# Run prediction on each group\n",
    "results=holdout_data.groupby([\"event.id\",\"clean_categories.name\"]).apply(evaluate, pipeline_file)\n",
    "\n",
    "# Display the results, uncomment this for your own display\n",
    "results.reset_index()['score'].plot.bar();\n",
    "\n",
    "# This is the student final grade\n",
    "print(np.average(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c1c22-8377-4355-a361-68c9e371ac72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1775cfb-c987-4f75-b9fb-54af1b171cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
